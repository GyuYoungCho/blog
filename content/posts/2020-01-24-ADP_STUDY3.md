---
title : "ADP 공부하기 3"
category :
    - ADP
tag :
    - ADP
toc : true
---

# 정형 데이터마이닝

## 1. 데이터 마이닝 개요

### 변수 선택

**filter method**
- 각각의 변수들에 대해 통계적 점수 부여, 점수로 순위를 매김
- chi squared, information gain, correlatioin 등

**wrapper method**
- 변수 간 상호 작용 감지, 변수의 일부만 모델링에 사용 후 결과 평가 -> 반복
- recursive feature elimination algorithm

**embedded method**
- filter method와 wrapper method 결합, 과적합을 줄이기 위해 내부적 규제
- ridge, lasso, elastic net
- wrapper는 학습을 마친 후 비교, embedded는 학습 과정에서 최적화된 변수 선택

### 머신러닝
- 지도학습, 비지도학습, 강화학습
**지도학습** : knn, 선형회귀, svm, 의사결정 나무, 신경망
**비지도학습** : 군집분석, pca, 연관분석, 사회연결망 분석, 텍스트 마이닝

### 딥러닝
**DNN** : 인공신경망(ANN)에서 은닉층이 여러개
    - 암 진단 시스템, 주가지수예측, 환율예측, 기업신용평가
**CNN** : 다계층 퍼셉트론, 여러 개의 합성곱 계층과 인공 신경망 계층으로 이루어짐
    - 자율 주행 자동차, 멀티미디어 식별
**RNN** : 시간의 흐름에 따른 따른 데이터 학습, 기준 시점과 다음 시점의 네트워크 연결
    - 음성 인식, 번역, 의미 판단, 이미지 캡션 생성, 자연어 처리

#### 딥러닝 지원 라이브러리
#### 파이썬
**theano**
- keras : 오픈 소스 신경망 라이브러리, dnn의 빠른 실험
- lasagne : theano의 복잡성을 추상화하고 보다 편리한 인터페이스

**chainer** : "define-by-run"모델을 기반으로 NLP에서 많이 이용
**TENSORFLOW** : 구글에서 만든 오픈소스 패키지, 플로우 그래프
**CXXNET** : MShadow 라이브러리, 멀티GPU지원
#### C++
- caffe : 이미지 분석에 특화
- mxnet : 파이썬도 지원, 대규모 데이터셋에 효과적, 아마존 웹 서비스에서 딥러닝 프레임워크 지원
#### JAVA
deepLearning4j : 비즈니스용 딥러닝 플랫폼
#### R
darch, deepnet
---

<br>

## 2. 분류 분석

### 나이브 베이즈
$$posterior = \frac{prior \times likelihood}{evidence}$$
- 문서를 여러 범주(스팸,스포츠) 중 하나로 판단
- 다른 속성들이 독립적 : **클래스 조건 독립성**

### K-NN
**유클리디안(대표적)**, 맨하탄, 민코우스키 거리 사용
유클리디안 : 두 점 거리 제곱합의 제곱근
맨하탄 : 절대값
- 장점 : 사용 간단, 기준을 몰라도 데이터 분류 가능, 데이터 처리가 용이
- 단점 : k값 결정이 어렵, 비수치 데이터일 경우 유사도 정의 어렵, 이상치가 있으면 큰 영향을 받음

### SVM
새로운 데이터가 어떤 범주에 속하는지 판단하는 **비확률적 이진 선형 분류모델**을 생성
- 가장 큰 폭을 가진 경계를 찾음

**초평면** : 각 그룹을 구분하는 분류자
**서포트 벡터** : 초평면에 가장 가까이에 붙어있는 최전방 데이터
**마진** : 포여면과 서포트 벡터 사이의 수직거리

**마진을 최대화하는 초평면(MMH)을 찾아 수행**
- 비선형 분류에서는 **커널 트릭** 사용
- 장점 : 분류, 예측 모두 가능, 과적합 정도 적음, 정확도가 높다, 저차원 고차원 상관없이 잘 작동
- 단점 : 전처리와 매개변수 설정에 따라 정확도가 달라짐, 해석이 어려움, 속도가 느리고, 할당량이 크다.

---

<br>

## 군집분석

### resampling
**k-fold cross validation**
k-1개 집단으로 학습, 1개로 성능 테스트 -> k번 반복-> mse평균
**bootstrap**
표본에 대해 다시 재표본을 여러 번 추출, 단순랜덤 복원추출법 사용
- 63.2%만 선택, 나머지 OOB 데이터(OOB-error: 실제값과 예측값 사이 오차)

### 군집화 기법
#### 밀도기반 군집분석
어느 점을 기준으로 반경 내에 최소 개수만큼의 데이터들은 가질 수 있도록 밀도에 의해 군집을 형성
- DBSCAN : 밀도 한계점에 따라 군집 형성(대표적)
- OPTICS : 군집화 구조 식별을 위해 부가적 순서를 생성
- DENCLUE : 밀도 분포함수에 기초

#### 격자기반
데이터가 존재하는 공간을 격자구조로 이루어진 유한개의 셀들로 양자화하여 셀을 이용해 군집화, 셀의 수에만 의존
- STING : 결자 셀에 저장된 통계정보를 탐색
- Wavecluster : Wavelet변환 기법 사용
- CLIQUE : 고차원 데이터 공간의 군집화를 위한 **격자 및 밀도기반**

### 군집 분석의 타당성 지표
**Silhouette(실루엣)**
- 군집 내의 응집도와 군집 간 분리도를 이용한 지표
- 군집 내 거리가 짧고 군집 간 거리가 멀수록 값이 커짐

**dunn index**
- 군집 간 거리는 멀고, 군집 내 분산은 작을수록 군집화가 잘 이루어짐
- dunn index가 클수록 군집이 잘 형성됨

### BMU
- SOM에서는 각 학습 단계마다 입력층으로부터 하나의 표본 벡터를 임의로 선택하고 경쟁층의 프로토타입 벡터와의 거리 계산
- 그 후 **표본 벡터와 거리가 가장 가까운 프로토타입 벡터**ㄹ르 선택
- BMU는 선택된 프로토타입 벡터를 나타내는 용어